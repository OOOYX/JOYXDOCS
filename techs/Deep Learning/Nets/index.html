<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
<title>网络结构 - JOYXDOCS</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="generator" content="mkdocs-1.5.3, mkdocs-gitbook-1.0.7">

<link rel="shortcut icon" href="../../../images/favicon.ico" type="image/x-icon">
<meta name="HandheldFriendly" content="true"/>
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<meta rel="next" href="" />
<link href="../../../css/style.min.css" rel="stylesheet"> 
</head>

<body>
<div class="book">
<div class="book-summary">
<div id="book-search-input" role="search">
<input type="text" placeholder="Type to search" />
</div> <!-- end of book-search-input -->

<nav role="navigation">
<ul class="summary">
<li>
<a href="../../.." target="_blank" class="custom-link">JOYXDOCS</a>
</li>
<li class="divider"></li>
<li class="chapter" data-path="">
<a href="../../..">封面</a>
<li class="header">技术积累</li>

<li>
<a href="#">网页开发</a>
<ul>

<li>
<a href="../../web_development/css/" class="">CSS</a>
</li>
</ul>
</li>

<li>
<a href="#">PyTorch</a>
<ul>

<li>
<a href="../../pytorch/tensor/" class="">Tensor</a>
</li>
</ul>
</li>

<li>
<a href="#">DeepLearning</a>
<ul>

<li>
<a href="./" class="active">网络结构</a>
</li>

<li>
<a href="../%E5%9F%BA%E4%BA%8E%E6%BD%9C%E5%9C%A8%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9B%BE%E5%83%8F%E5%90%88%E6%88%90/" class="">基于潜在扩散模型的图像合成</a>
</li>

<li>
<a href="../Transformer/" class="">Transformer</a>
</li>
</ul>
</li>

<li class="header">其他</li>

<li>
<a href="#">Academic Writing</a>
<ul>

<li>
<a href="../../../other/academic_writing/L1/" class="">Lesson1</a>
</li>

<li>
<a href="../../../other/academic_writing/L2/" class="">Lesson2</a>
</li>

<li>
<a href="../../../other/academic_writing/L3/" class="">Lesson3</a>
</li>

<li>
<a href="../../../other/academic_writing/L4/" class="">Lesson4</a>
</li>
</ul>
</li>

<li class="divider"></li>



<li><a href="http://www.mkdocs.org">
Published with MkDocs
</a></li>

<li><a href="https://github.com/GitbookIO/theme-default">
Theme by GitBook
</a></li>
</ul>

</nav>

</div> <!-- end of book-summary -->

<div class="book-body">
<div class="body-inner">
<div class="book-header" role="navigation">

<!-- Title -->
<h1>
<i class="fa fa-circle-o-notch fa-spin"></i>
<a href="." ></a>
</h1>

</div> <!-- end of book-header -->

<div class="page-wrapper" tabindex="-1" role="main">
<div class="page-inner">
<div id="book-search-results">
<div class="search-noresults">

<section class="normal markdown-section">



<h2 id="_1">池化和卷积的异同</h2>
<ul>
<li>池化保留重要特征（聚合特征），降维，过滤噪声</li>
<li>卷积提取特征</li>
</ul>
<h2 id="alexnet">AlexNet</h2>
<ul>
<li><strong>使用ReLU激活函数</strong>：相比传统的 Sigmoid 或 Tanh 激活函数，ReLU 在训练深层网络时能更有效地防止梯度消失的问题。为了避免“死亡ReLU”问题（神经元的输入始终小于0，则该神经元的输出和梯度始终为0），可以使用Leaky ReLU或PReLU来代替ReLU。</li>
<li><strong>使用Dropout技术</strong>：以一定的概率临时丢弃网络中的部分神经元，防止模型过拟合。</li>
<li><strong>局部响应归一化 (LRN)</strong>：尽管后来的研究表明 LRN 并非必需，但在当时，这一技术被认为能提升模型的泛化能力。</li>
<li><strong>重叠的池化层</strong>：AlexNet 使用的池化层步长小于池化核尺寸，增加了特征的重叠和覆盖范围，有助于提取更多的特征信息。</li>
</ul>
<h2 id="vggnet">VGGNet</h2>
<ul>
<li><strong>统一的卷积层设计</strong>：VGGNet 采用了多个相同尺寸的卷积核（主要是 3x3），层与层之间只通过增加卷积核的数量来扩展网络深度。</li>
<li><strong>更深的网络结构</strong>：通过重复使用小卷积核和增加网络深度，VGGNet 能够在保持较小感受野的同时，捕捉更复杂的图像特征。</li>
<li><strong>使用MaxPooling</strong>：在卷积层组之间使用最大池化层进行下采样，减少特征维度，减轻计算负担。</li>
</ul>
<h2 id="resnet">ResNet</h2>
<p>网络结构上，ResNet是在普通网络层之间增加了短路连接。即在下图中，添加了x支路。</p>
<p><img alt="img" src="https://i-blog.csdnimg.cn/blog_migrate/9799d2b846583581f8ecb964e968f657.png" /></p>
<p>ResNet能够较好地解决层数增加时带来的梯度消失或梯度爆炸的问题，从而能构建有效的更多层数的网络。</p>
<h2 id="deconvnet">DeconvNet</h2>
<p>反卷积网络，用于可视化CNN内部特征。</p>
<h2 id="unet">UNet</h2>
<p>适用于图像中的精确局部化任务，尤其是在数据量相对较少的情况下。</p>
<p><img alt="在这里插入图片描述" src="https://i-blog.csdnimg.cn/blog_migrate/e9e66db52f4aaeedfd5e151f993be781.png" /></p>
<p>由于网络形状像‘U’，所以被称为U-Net</p>
<ol>
<li>conv 3x3,ReLu就是卷积层，其中卷积核大小是3x3，然后经过ReLu激活。</li>
<li>copy and crop的意思是复制和裁剪。这块内容我觉得很多人最初和我一样，不明白是什么意思，这里的意思就是对于你输出的尺寸，你需要进行复制并进行中心剪裁。方便和后面上采样生成的尺寸进行拼接。</li>
<li>max pool 2x2，就是最大池化层，卷积核为2x2。</li>
<li>up-conv 2x2：反卷积层。</li>
<li>conv 1x1：卷积层，卷积核大小是1x1。</li>
</ol>


</section>
</div> <!-- end of search-noresults -->
<div class="search-results">
<div class="has-results">

<h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
<ul class="search-results-list"></ul>

</div> <!-- end of has-results -->
<div class="no-results">

<h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>

</div> <!-- end of no-results -->
</div> <!-- end of search-results -->
</div> <!-- end of book-search-results -->

</div> <!-- end of page-inner -->
</div> <!-- end of page-wrapper -->

</div> <!-- end of body-inner -->

</div> <!-- end of book-body -->
<script src="../../../js/main.js"></script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<script src="../../../_js/configure-mathjax.js"></script>
<script src="../../../search/main.js"></script>
<script src="../../../js/gitbook.min.js"></script>
<script src="../../../js/theme.min.js"></script>
</body>
</html>