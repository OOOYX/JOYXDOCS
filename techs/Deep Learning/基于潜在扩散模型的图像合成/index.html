<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="text/html; charset=utf-8" http-equiv="Content-Type">
<title>基于潜在扩散模型的图像合成 - JOYXDOCS</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<meta name="generator" content="mkdocs-1.5.3, mkdocs-gitbook-1.0.7">

<link rel="shortcut icon" href="../../../images/favicon.ico" type="image/x-icon">
<meta name="HandheldFriendly" content="true"/>
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black">
<meta rel="next" href="" />
<link href="../../../css/style.min.css" rel="stylesheet"> 
</head>

<body>
<div class="book">
<div class="book-summary">
<div id="book-search-input" role="search">
<input type="text" placeholder="Type to search" />
</div> <!-- end of book-search-input -->

<nav role="navigation">
<ul class="summary">
<li>
<a href="../../.." target="_blank" class="custom-link">JOYXDOCS</a>
</li>
<li class="divider"></li>
<li class="chapter" data-path="">
<a href="../../..">封面</a>
<li class="header">技术积累</li>

<li>
<a href="#">网页开发</a>
<ul>

<li>
<a href="../../web_development/css/" class="">CSS</a>
</li>
</ul>
</li>

<li>
<a href="#">PyTorch</a>
<ul>

<li>
<a href="../../pytorch/tensor/" class="">Tensor</a>
</li>
</ul>
</li>

<li>
<a href="#">DeepLearning</a>
<ul>

<li>
<a href="../Nets/" class="">网络结构</a>
</li>

<li>
<a href="./" class="active">基于潜在扩散模型的图像合成</a>
</li>

<li>
<a href="../Transformer/" class="">Transformer</a>
</li>
</ul>
</li>

<li class="header">其他</li>

<li>
<a href="#">Academic Writing</a>
<ul>

<li>
<a href="../../../other/academic_writing/L1/" class="">Lesson1</a>
</li>

<li>
<a href="../../../other/academic_writing/L2/" class="">Lesson2</a>
</li>

<li>
<a href="../../../other/academic_writing/L3/" class="">Lesson3</a>
</li>

<li>
<a href="../../../other/academic_writing/L4/" class="">Lesson4</a>
</li>
</ul>
</li>

<li class="divider"></li>



<li><a href="http://www.mkdocs.org">
Published with MkDocs
</a></li>

<li><a href="https://github.com/GitbookIO/theme-default">
Theme by GitBook
</a></li>
</ul>

</nav>

</div> <!-- end of book-summary -->

<div class="book-body">
<div class="body-inner">
<div class="book-header" role="navigation">

<!-- Title -->
<h1>
<i class="fa fa-circle-o-notch fa-spin"></i>
<a href="." ></a>
</h1>

</div> <!-- end of book-header -->

<div class="page-wrapper" tabindex="-1" role="main">
<div class="page-inner">
<div id="book-search-results">
<div class="search-noresults">

<section class="normal markdown-section">



<h1 id="_1">扩散模型</h1>
<blockquote>
<p>本篇内容基于论文High-Resolution Image Synthesis with Latent Diffusion Models，Robin Rombach，Andreas Blattmann，Dominik Lorenz，Patrick Esser，Bjorn Ommer</p>
</blockquote>
<p><img alt="image-20240817024641603" src="../../../imgs/image-20240817024641603.png" /></p>
<p>上图显示了训练模型的速率失真权衡（the rate-distortion trade-offl）。</p>
<p>失真情况（纵轴）随着学习率（横轴）的变化分为两个阶段：</p>
<ol>
<li><strong>Perceptual Compression 感知压缩阶段</strong>：消除了高频细节</li>
<li><strong>Semantic Compression 语义压缩阶段</strong>：实际的生成模型学习数据的语义和概念组成</li>
</ol>
<p>我们的目标是找一个<strong>感知上等效但计算上更合适的位置</strong>（即接近转折点处），在这个位置训练用于高分辨率图像合成的扩散模型。</p>
<h2 id="_2">模型原理</h2>
<p><img alt="image-20240817024652851" src="../../../imgs/image-20240817024652851.png" /></p>
<h3 id="perceptual-image-compression">Perceptual Image Compression 感知图像压缩</h3>
<ul>
<li>编码器<span class="arithmatex">\(\epsilon\)</span>：<span class="arithmatex">\(z = \epsilon(x)\)</span>, 其中 <span class="arithmatex">\(x\in \mathbb{R}^{H\times W\times 3}\)</span>为图像的RGB向量表示, <span class="arithmatex">\(z\in \mathbb{R}^{h\times w\times c}\)</span></li>
<li>
<p>解码器D：<span class="arithmatex">\(\hat{x} = D(z) = D(\epsilon(x))\)</span></p>
</li>
<li>
<p>下采样因数<span class="arithmatex">\(f = H/h = W/w\)</span>, 通常使用<span class="arithmatex">\(f = 2^m, m\in\mathbb{N}\)</span></p>
</li>
</ul>
<p>在此变换基础上，可以由扩散模型的损失函数（1）得到<strong>潜在扩散模型的损失函数</strong>（2）</p>
<p><img alt="屏幕截图 2024-08-17 024302" src="../../../imgs/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-08-17%20024302.png" /></p>
<p><img alt="屏幕截图 2024-08-17 024326" src="../../../imgs/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-08-17%20024326.png" /></p>
<p>其中：</p>
<ul>
<li><span class="arithmatex">\(\mathbb{E}_{x,\epsilon\sim\Nu(0,1),t}\)</span>表示在所有 x，噪声 ϵ（服从标准正态分布 (0,1)N(0,1)），和时间步 t 上取平均。</li>
<li>$ \epsilon_{\theta}(x(t), t) $表示模型预测的噪声</li>
<li><span class="arithmatex">\(\|\epsilon - \epsilon_{\theta}(x(t), t)\|^2\)</span>表示平方欧几里得距离，用于衡量模型预测的噪声与真实噪声之间的差异</li>
</ul>
<p>这个损失函数的目标是最小化模型预测的噪声和真实噪声之间的差异。通过这种方式，模型学习如何逆转扩散过程，即从噪声数据 <span class="arithmatex">\( x(t) \)</span> 重构出原始数据 <span class="arithmatex">\( x \)</span>。这是通过优化模型参数 <span class="arithmatex">\( $\theta$ \)</span> 来实现的，使得预测的噪声尽可能接近实际添加到数据中的噪声。</p>
<h3 id="conditioning-mechanism">Conditioning Mechanism 调节机制</h3>
<p>通过结合扩散模型（DMs）和其他类型的条件输入，可以提高生成模型处理不同任务的能力。调节机制增强了U-Net基础架构，并引入了注意力机制。</p>
<p><img alt="屏幕截图 2024-08-17 024326" src="../../../imgs/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-08-17%20024342.png" /></p>
<p>Q，K，V是注意力机制的三个基本组成部分，这使模型能够基于输入的不同特征（由K和V表示）对信息（由Q查询）进行加权和整合。</p>
<ul>
<li>
<p><span class="arithmatex">\(\varphi_i(z_t)\)</span>：U-Net模型的一个中间表示</p>
</li>
<li>
<p><span class="arithmatex">\(\tau\)</span>: 输入 <em>y</em> 的一个域特定的预处理函数, y为模型输入的条件</p>
</li>
<li><span class="arithmatex">\(W_Q,W_K,W_V\)</span>是可学习的投影矩阵</li>
</ul>
<p>据此可以把公式（2）扩展到公式（3），引入条件<span class="arithmatex">\(\tau_{\theta}(y)\)</span></p>
<p><img alt="屏幕截图 2024-08-17 024359" src="../../../imgs/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE%202024-08-17%20024359.png" /></p>
<h2 id="_3">实验</h2>
<h3 id="1-f">1. 在感知压缩中调整下采样因数f</h3>
<p>分析下面的训练数据图发现：</p>
<ol>
<li>LDM-{1,2} 的小下采样因子会导致训练进度缓慢</li>
<li>f 值过大会导致在相对较少的训练步骤后保真度停滞不前</li>
</ol>
<p><img alt="image-20240820093855494" src="../../../imgs/image-20240820093855494.png" /></p>
<ul>
<li><strong>Fréchet Inception Distance (FID)</strong>: 这个指标衡量的是模型生成的图像与真实图像在特征空间内的距离，这个特征空间由Inception网络提取。FID值越低，表示生成的图像与真实图像在统计特性上越接近，质量越高。</li>
</ul>
<p>将这一现象归因于：</p>
<ol>
<li>将大部分感知压缩留给扩散模型</li>
<li>第一阶段压缩过强导致信息丢失，从而限制了可实现的质量</li>
</ol>
<h3 id="2-ldm">2. 使用LDM进行图像生成</h3>
<script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  }
};
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>


</section>
</div> <!-- end of search-noresults -->
<div class="search-results">
<div class="has-results">

<h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
<ul class="search-results-list"></ul>

</div> <!-- end of has-results -->
<div class="no-results">

<h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>

</div> <!-- end of no-results -->
</div> <!-- end of search-results -->
</div> <!-- end of book-search-results -->

</div> <!-- end of page-inner -->
</div> <!-- end of page-wrapper -->

</div> <!-- end of body-inner -->

</div> <!-- end of book-body -->
<script src="../../../js/main.js"></script>
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<script src="../../../_js/configure-mathjax.js"></script>
<script src="../../../search/main.js"></script>
<script src="../../../js/gitbook.min.js"></script>
<script src="../../../js/theme.min.js"></script>
</body>
</html>